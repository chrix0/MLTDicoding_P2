# -*- coding: utf-8 -*-
"""Proyek Akhir.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11KSsb_TkVTaaer_wufgPKjtxbQ1wHYH_

# **Data Diri**
* Nama Lengkap: Chris Tianto Pratama
* Username: chrix0n
* Email: christiantopratama@gmail.com



---

# **Import**


---
"""

!pip install scikit-surprise

import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import seaborn as sns
from pathlib import Path
import matplotlib.pyplot as plt
import statistics
import itertools

from collections import defaultdict
from surprise.model_selection import GridSearchCV
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from surprise import Dataset, SVD, KNNBasic, KNNBaseline, NMF, SlopeOne, Reader
from surprise.model_selection import cross_validate
from surprise.model_selection import train_test_split
from collections import Counter

sns.set()

"""# **Data Loading**


---

Link halaman dataset MovieLens: https://grouplens.org/datasets/movielens/

Link download dataset MovieLens (Small): https://files.grouplens.org/datasets/movielens/ml-latest-small.zip
"""

!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip

!unzip /content/ml-latest-small.zip

"""Dataset ini berisi kumpulan subdataset, yaitu:
- movies (data film)
- ratings (data rating oleh pengguna)
- links (link sumber data film)
- tags (tag yang diberikan oleh pengguna terhadap film)
"""

movies = pd.read_csv('/content/ml-latest-small/movies.csv')
ratings = pd.read_csv('/content/ml-latest-small/ratings.csv')
links = pd.read_csv('/content/ml-latest-small/links.csv')
tags = pd.read_csv('/content/ml-latest-small/tags.csv')

"""Dataset yang akan digunakan dalam proyek ini:
- movies
- ratings


"""

movies

ratings

"""# **Data Understanding (Exploratory Data Analysis)**


---

**1. Deskripsi Variabel**

**Movies**

| Nama fitur | Deskripsi | Tipe data |
|---|---|---|
|movieId| ID dari film berdasarkan website [TMDB](https://www.themoviedb.org) |int64|
|title| Judul film |object|
|genres| Genre film, yang dipisah dengan tanda pipe ('\|') |object|

Jumlah data pada dataset movies: 9742
"""

movies.info()

"""**Ratings**

| Nama fitur | Deskripsi | Tipe data |
|---|---|---|
|userId| ID dari pengguna website MovieLens yang memberikan rating|int64|
|movieId| ID dari film yang diberi rating |int64|
|rating| Nilai yang diberikan dalam skala 0.5 - 5, dengan peningkatan nilai sebesar 0.5 |float64|
|timestamp| Waktu pemberian rating dalam satuan detik |int64|

Jumlah data pada dataset ratings: 100836
"""

ratings.info()

"""Fitur timestamp tidak digunakan dalam pemberian rekomendasi, sehingga fitur tersebut dihapus dalam dataset ratings."""

ratings = ratings.drop('timestamp', axis=1)

ratings.info()

"""**2. Pemeriksaan Missing Value**

Movies
"""

movies.isnull().sum()

"""Rating"""

ratings.isnull().sum()

"""Tidak ada data dengan missing value pada dataset movies dan ratings

**3. Univariate Analysis**

**3.1 Movies**

**Fitur movieID**
"""

print('Jumlah movieID unik: ', len(movies.movieId.unique()))

"""Terdapat 9742 movie ID unik dalam dataset movies. Jumlah movieID unik sama dengan jumlah data pada dataset movies, sehingga dapat dipastikan bahwa setiap data memiliki movie ID yang berbeda.

**Fitur title**
"""

print('Jumlah title unik: ', len(movies.title.unique()))

"""Terdapat 9737 judul film unik dalam dataset movies. Jumlah title unik lebih sedikit daripada jumlah data pada dataset movies. Hal ini menunjukkan bahwa terdapat 5 judul duplikat.

**Fitur genre**
"""

print('Jumlah genre: ', len(movies.genres.unique()))

"""Genre yang tersedia"""

movies['genres'].value_counts()

"""Data dengan genre lebih dari satu terlihat dipisah dengan tanda " | ". Untuk mendapatkan genre-genre tersebut secara terpisah, semua nilai dalam kolom genre diubah menjadi array yang berisi string, lalu hitung jumlah kemunculan genre."""

movies['genres']= movies['genres'].str.split("|")

movies['genres']

flat_list = list(itertools.chain(*movies['genres']))
counter_of_flat_list = Counter(flat_list)
genre_stat = pd.DataFrame(counter_of_flat_list.most_common(), columns=['Genre', 'Jumlah data'])
genre_stat

genre_stat.head(20).set_index('Genre').sort_values(ascending=True, by="Jumlah data").plot(kind='barh', title="Jumlah Data Berdasarkan Genre", figsize=[15,10])

plt.show()

genre_stat['persentase'] = ((genre_stat['Jumlah data'] / genre_stat['Jumlah data'].sum()) * 100).round(2)
genre_stat

"""Fitur rating terdiri atas 19 nilai unik, yaitu Drama, Comedy, Thriller, Action, Romance, Adventure, Crime, Sci-Fi, Horror, Fantasy, Children, Animation, Mystery, Documentary, War, Musical, Western, IMAX, Film-Noir, dan genre kosong (no genres listed). Genre dengan jumlah film terbanyak di dalam dataset adalah Drama.

**3.2 Ratings**

**Fitur userId**
"""

print('Jumlah userId unik: ', len(ratings.userId.unique()))

"""Terdapat 610 userId pada dataset ratings. Hal ini menunjukkan bahwa 610 pengguna secara keseluruhan telah membuat 100836 rating."""

ratings.userId.value_counts().to_frame(name="Jumlah rating")

ratings.userId.value_counts().to_frame(name="Jumlah rating").head(10).plot(kind="bar", title="10 Pengguna dengan Jumlah Rating Terbanyak", rot= 0)

"""Stastistik deskriptif jumlah pemberian rating setiap pengguna."""

ratings.userId.value_counts().to_frame(name="Jumlah rating").describe()

"""Pengguna yang memberikan rating terbanyak adalah pengguna dengan userId 414, yang telah membuat 2698 rating. Pengguna dengan jumlah rating yang paling sedikit dalam dataset ini adalah 20.

**Fitur movieId**
"""

print('Jumlah movieId unik yang diberi rating: ', len(ratings.movieId.unique()))

"""Terdapat 9724 movieId pada dataset rating. Jumlah film yang dirating tidak sama dengan jumlah film keseluruhan pada dataset movies sebelum penghapusan data (9742 movieID). Hal ini menunjukkan bahwa terdapat film yang belum diberi rating.

**Fitur rating**
"""

print('Jumlah kemungkinan pemberian rating: ', len(ratings.rating.unique()))

ratings.rating.unique()

"""Terdapat 10 kemungkinan nilai yang dapat diberikan dalam pemberian rating, yaitu 5.0, 4.5, 4.0, 3.5, 3.0, 2.5, 2.0, 1.5, 1.0, dan 0.5. Hal ini menunjukkan bahwa skala rating yang digunakan adalah 0.5 - 5.0."""

ratings.rating.value_counts().sort_index().to_frame(name="Jumlah data berdasarkan rating")

ratings.rating.value_counts().sort_index().plot(kind="bar", title="Jumlah Data Berdasarkan Rating", rot=0)

"""Grafik di atas menunjukkan jumlah data berdasarkan rating dari yang terbanyak hingga yang paling sedikit. Jumlah data terbanyak adalah data yang memberikan rating 4.0, sedangkan jumlah data paling sedikit adalah data yang memberikan rating 0.5.

# **Data Preparation**

**1. Penanganan judul film duplikat pada dataset movies**

Pada tahap ini, data film dengan judul duplikat akan dihapus. Tahap ini bertujuan untuk mencegah pemberian dua rekomendasi film yang sama oleh model Content Based Filtering dan Collaborative Filtering.
"""

judul = movies['title'].value_counts()
judul_duplikat = judul[judul > 1].to_frame().reset_index()
judul_duplikat.columns = ['title', 'jumlah data']

judul_duplikat

movies[movies.duplicated(keep=False, subset=['title'])]

"""Salah satu judul film duplikat akan dihapus."""

movies.drop_duplicates('title', keep='last')

movies = movies.drop_duplicates('title', keep='last')

movies[movies.duplicated(keep=False, subset=['title'])]

movies.shape

"""Data dengan judul film duplikat telah dihapus. Jumlah data telah berkurang dari 9742 menjadi 9737.

**2. Penanganan terhadap data film yang memiliki tidak memiliki genre pada dataset movies**

Pada tahap ini, semua data film yang memiliki genre kosong (*no genres listed*) akan dihapus. 34 data dengan genre kosong (no genres listed) perlu dihapus dalam dataset movies. Tahap ini bertujuan untuk mencegah pemberian rekomendasi film tanpa genre kepada pengguna oleh model Content Based Filtering, karena ada kemungkinan bahwa film yang direkomendasikan tidak sesuai dengan preferensi pengguna.
"""

movies[movies.genres.str.contains('(no genres listed)', regex=False)]

movies = movies[~(movies.genres.str.contains('(no genres listed)', regex=False))]

movies

"""Data dengan genre '(no genres listed)' telah dihapus. Jumlah data telah berkurang dari 9737 menjadi 9703.

**3. Penggabungan dataset movies dengan ratings**

Pada tahap ini, data movies dan ratings akan digabungkan berdasarkan movieId. Tahap ini bertujuan untuk menunjukkan data film yang belum memiliki rating dan mempersiapkan data sebelum melakukan pelatihan model Content Based Filtering.
"""

movie_ratings = pd.merge(movies, ratings, on='movieId', how='left')

movie_ratings

"""**4. Penanganan terhadap data film yang belum memiliki rating**

Pada tahap ini, data yang belum memiliki rating pada dataset gabungan movies dan ratings akan dihapus. Tahap ini bertujuan untuk mencegah pemberian rekomendasi film yang belum memiliki rating oleh model Collaborative Filtering.
"""

rating_mean = movie_ratings.groupby('title')['movieId','title','rating'].mean().round(2).sort_values(ascending = False, by='rating')
rating_mean['movieId']= rating_mean['movieId'].astype(np.int64) # movieId diubah dari float64 menjadi int64
rating_mean

"""Dataframe di atas menunjukkan bahwa terdapat film yang belum diberi rating (NaN)."""

rating_mean[rating_mean['rating'].isnull()]

"""Data-data yang tidak memiliki rating perlu dihapus."""

rating_mean = rating_mean[~rating_mean['rating'].isnull()]
rating_mean

"""Jumlah data telah berkurang dari 9703 menjadi 9685.

Fitur genre ditambahkan ke dalam rating_mean berdasarkan movieId.
"""

movie_ratings = pd.merge(movies, rating_mean, on='movieId', how='inner')
movie_ratings

"""Dataframe ini akan digunakan dalam menampilkan hasil rekomendasi dengan Content Based Filtering dan Collaborative Filtering.

**5. Pembagian data training dan data testing pada dataset ratings**

Pada tahap ini, dataset ratings dibagi menjadi dua bagian, yaitu data training (`trainset`) dan data testing (`testset`). Tahap ini bertujuan untuk mempersiapkan data ratings yang akan digunakan dalam pelatihan dan pengujian model Collaborative Filtering dengan metode [Cross Validation yang disediakan oleh library  Surprise](https://surprise.readthedocs.io/en/stable/model_selection.html#module-surprise.model_selection.split).
"""

reader = Reader(rating_scale=(1, 5))

#Ubah dataframe Pandas menjadi dataframe Surprise
s_ratings = Dataset.load_from_df(ratings[["userId", "movieId", "rating"]], reader)
trainset = s_ratings.build_full_trainset()
testset = trainset.build_anti_testset()

"""# **Model Development**

**1. Content Based Filtering**

**1.1 TF-IDF**
"""

#Preprocessing dan tokenizing tidak diperlukan karena fitur genre sudah berupa array string yang sudah dipisah-pisah.
tf = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x) 
tf_matrix = tf.fit_transform(movie_ratings['genres']) 
tf_feat = tf.get_feature_names()
tf_feat

tf_matrix.shape

"""**Menampilkan matriks TF-IDF untuk 15 sampel**"""

tf_idf = pd.DataFrame(
    tf_matrix.todense(), 
    columns=tf_feat,
    index=movie_ratings['title']
).sample(19, axis=1).sample(15, axis=0)
tf_idf

"""**1.2 Cosine Similiarity**"""

cosine_sim = cosine_similarity(tf_matrix)

"""Kemiripan 5 data film dengan data film lainnya."""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_ratings['title'], columns=movie_ratings['title'])
print('Shape:', cosine_sim_df.shape)
cosine_sim_df.sample(5, axis=1).round(2).head(5)

"""**Pemberian rekomendasi**

Metode genre_recommendations digunakan untuk memberikan rekomendasi dengan jumlah k.
"""

def genre_recommendations(title, sim_df, items, k=1):
    ix = sim_df.loc[:,title].to_numpy().argpartition(range(-1,-k,-1))
    closest = sim_df.columns[ix[-1:-(k+2):-1]]
    closest = closest.drop(title, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

"""Contoh hasil rekomendasi Content Based Filtering dengan Top-5 recommendation"""

movie_ratings[movie_ratings.title == 'Jumanji (1995)']

genre_recommendations('Jumanji (1995)', cosine_sim_df, movie_ratings[['title', 'movieId', 'genres', 'rating']], 5)

movie_ratings[movie_ratings.title == 'No Game No Life: Zero (2017)']

genre_recommendations('No Game No Life: Zero (2017)', cosine_sim_df, movie_ratings[['title', 'movieId', 'genres', 'rating']], 5)

"""**2. Collaborative Filtering**

Algoritma SVD dan KNN akan dibandingkan untuk menentukan model dengan algoritma yang dapat menghasilkan rekomendasi terakurat.

**Hyperparameter tuning**
"""

#List algo yang digunakan dengan parameter-parameter yang akan diuji
algo = {
        'SVD': {
            'model': SVD,
            'param': {
                "n_factors": [50, 80, 100], 
                "lr_all": [0.0035, 0.005, 0.01], 
                "reg_all": [0.01, 0.02, 0.4]
            }
        },
        'KNNBasic': {
            'model': KNNBasic,
            'param': {
                'k': [40, 60, 80, 100],
                'min_k': [1, 2, 3, 4, 5]
            }
        }
    }

data = Dataset.load_from_df(ratings[["userId", "movieId", "rating"]], reader)

res = []
for nama, prop in algo.items():
  grid = GridSearchCV(prop['model'], prop['param'], n_jobs = -1, measures=["rmse", "mae"], cv=5, joblib_verbose=10)
  grid.fit(data)
  res.append({
      'model': nama,
      'best_score': grid.best_score,
      'best_params': grid.best_params
  })

pd.DataFrame(res)

svd = SVD(n_factors= 50, lr_all= 0.005, reg_all= 0.02)

knn = KNNBasic(k= 40, min_k= 2)

"""**Training Model**"""

svd.fit(trainset)
knn.fit(trainset)

"""**Pemberian rekomendasi**

Metode untuk menampilkan rekomendasi dalam bentuk Top-N
"""

def get_top_n(predictions, n=10):
    # First map the predictions to each user.
    top_n = defaultdict(list)
    for uid, iid, true_r, est, _ in predictions:
        top_n[uid].append((iid, est))

    # Then sort the predictions for each user and retrieve the k highest ones.
    for uid, user_ratings in top_n.items():
        user_ratings.sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = user_ratings[:n]

    return top_n

"""Metode untuk membuat Top-10 rekomendasi film untuk user tertentu"""

def show_rec(userId, prediction, n):
  top_n = get_top_n(prediction, n)
  for uid, user_ratings in top_n.items():
    if(uid == userId):
      return {
          'user': uid,
          'recommend': [iid for (iid, _) in user_ratings]
      }

prediction_svd = svd.test(testset)
prediction_knn = knn.test(testset)

"""10 film yang diberi rating tertinggi oleh user dengan ID 610"""

user = 610

ratings_mod = ratings

ratings_610 = ratings[ratings.userId == user]
ratings_610 = ratings_610.drop(columns=['userId'])
ratings_610 = ratings_610.rename(columns={'rating': 'rating user 610'})

filter_610 = movie_ratings[movie_ratings.movieId.isin(ratings_610['movieId'])]
filter_610 = filter_610.rename(columns={'rating': 'rating rata-rata'})

filter_merge = filter_610.merge(ratings_610, how='left', on='movieId').sort_values(by='rating user 610', ascending=False).head(10)
filter_merge

"""Top 10 rekomendasi film yang diberikan kepada user dengan ID 610"""

res_svd = show_rec(user, prediction_svd, 10)
res_svd

res_knn = show_rec(user, prediction_knn, 10)
res_knn

"""Hasil rekomendasi diberikan dalam bentuk array yang berisi movieId. Oleh karena itu, data film perlu dicari melalui dataframe movie_ratings yang dibuat telah sebelumnya berdasarkan movieId dari hasil rekomendasi tersebut."""

movie_ratings[movie_ratings.movieId.isin(res_svd['recommend'])]

movie_ratings[movie_ratings.movieId.isin(res_knn['recommend'])]

"""Kedua model tersebut menghasilkan rekomendasi yang sangat berbeda.

# **Evaluasi Model**

**1. Content Based Filtering**

Evaluasi Content Based Filtering dilakukan dengan metode "Precision at k" (Precision@k) terhadap genre yang direkomendasikan. Dalam kasus ini, k yang digunakan adalah 5.
"""

def precision_at_k(genre_true, df_prediksi, k=5):
  count = 0
  for i in df_prediksi['genres'].to_list():
    if (i == genre_true):
      count += 1
  precision = (count / k) * 100
  return precision

def pak_mean(sampel = [], sim_df = None, df = None):
  p_list = []
  for i in sampel:
    rec = genre_recommendations(i, sim_df, df, 5)
    find = df[df.title == i].genres.to_list()[0]
    p_list.append(precision_at_k(find, rec, 5))
  return {
      'P@k %': p_list,
      'mean': statistics.mean(p_list)
  }

"""Mengukur nilai P@K rata-rata dari 10 sampel"""

sampel_evaluasi = movie_ratings.sample(10)
sampel_evaluasi

arr = sampel_evaluasi['title'].to_list()
res_pak = pak_mean(arr, cosine_sim_df, movie_ratings)
pd.DataFrame(res_pak['P@k %'],  columns =['Nilai Prediction@k %'])

print("Mean Nilai P@k % = " + str(res_pak['mean']))

"""**2. Collaborative Filtering**

Evaluasi model Collaborative Filtering dilakukan dengan Cross Validation. Metrik evaluasi yang digunakan adalah RMSE dan MAE.
"""

svd_cv = cross_validate(svd, s_ratings, measures=["RMSE", "MAE"], cv=10, verbose=True)

svd_cv = cross_validate(knn, s_ratings, measures=["RMSE", "MAE"], cv=10, verbose=True)

"""Di antara kedua algoritma tersebut, algoritma SVD memiliki nilai mean RMSE dan MAE terendah, sehingga algoritma tersebut dapat memberikan hasil yang lebih akurat daripada algoritma KNN."""